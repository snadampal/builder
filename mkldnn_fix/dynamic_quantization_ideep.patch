From bb3cb9e62daa1d28cc5a2b59e874ae41c48d5a87 Mon Sep 17 00:00:00 2001
From: Sunita Nadampalli <nadampal@amazon.com>
Date: Sun, 3 Mar 2024 19:41:36 +0000
Subject: [PATCH] aarch64: ideep: dynamic quantization changes

---
 include/ideep/operators/matmul.hpp | 30 ++++++++++++++++++++++++------
 1 file changed, 24 insertions(+), 6 deletions(-)

diff --git a/include/ideep/operators/matmul.hpp b/include/ideep/operators/matmul.hpp
index af088e0..5a00ddc 100644
--- a/include/ideep/operators/matmul.hpp
+++ b/include/ideep/operators/matmul.hpp
@@ -706,10 +706,28 @@ struct matmul_forward : public dnnl::matmul,
     auto& weights_scales_in =
         weights.has_scale() ? weights.get_scale() : weights_scales;
     if (!weights_scales_in.empty()) { // for int8
-      do_prepare_static_quant<with_bias>(
-          param, src, weights, bias, dst,
-          src_scales, weights_scales, dst_scales, src_zero_points, dst_zero_points,
-          dst_coeff, sum_coeff, attr, dst_type, alowp_kind, aengine);
+      if (src.get_data_type() == data_type::f32) { // invoke dynamic quant
+        // prepare
+        do_prepare_dynamic_quant<with_bias>(param, src, weights,
+                              bias, dst, weights_scales, sum_coeff,
+                              attr, data_type::f32, aengine);
+        // compute
+        if (bias.is_empty()) {
+          do_compute_dynamic_quant</*with_bias=*/false, reorder_weight>(
+                              param, src, weights, bias, dst,
+                              src_scales, src_zero_points, dst_coeff, aengine);
+        } else {
+          do_compute_dynamic_quant</*with_bias=*/true, reorder_weight>(
+                              param, src, weights, bias, dst,
+                              src_scales, src_zero_points, dst_coeff, aengine);
+        }
+        return;
+      } else { // invoke static quant
+        do_prepare_static_quant<with_bias>(
+            param, src, weights, bias, dst,
+            src_scales, weights_scales, dst_scales, src_zero_points, dst_zero_points,
+            dst_coeff, sum_coeff, attr, dst_type, alowp_kind, aengine);
+      }
     } else {
       do_prepare<with_bias>(param, src, weights, bias, dst, dst_coeff, sum_coeff,
                  attr, dst_type, aengine);
@@ -1135,7 +1153,7 @@ struct matmul_forward : public dnnl::matmul,
     auto& weights_scales_in =
         weights.has_scale() ? weights.get_scale() : weights_scales;
 
-    auto src_data_type = data_type::u8;
+    auto src_data_type = data_type::s8;
     std::vector<int64_t> src_strides = (ndims == 3) ?
         std::vector<int64_t>({src_dims[1] * src_dims[2], src_dims[1], 1}) :
         std::vector<int64_t>({src_dims[1], 1});
@@ -1510,4 +1528,4 @@ struct matmul_forward : public dnnl::matmul,
 
 }  // namespace ideep
 
-#endif
\ No newline at end of file
+#endif
-- 
2.34.1

